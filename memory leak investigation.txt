Great. I’ll build a step-by-step plan that tackles three key goals:
1. **Diagnose and fix the current memory leak** in the WFL interpreter (with emphasis on parser and Environment/FunctionValue cycle).
2. **Validate fixes** using memory profiling (via `heaptrack`) and automated tests.
3. **Prevent recurrence** via structural improvements, test automation, and best practices.

I’ll include actionable steps for introducing `Weak` references, parser memory optimization, collection truncation, and automated regression testing.

I’ll get started on this and let you know once it’s ready to review.

# Memory Leak Mitigation Plan for the WFL Interpreter

## Root Cause Diagnosis

**Heap Profiling Findings:** Running the WFL interpreter on the comprehensive test script (`nexus.wfl`) revealed **extremely high memory usage** – peaking around 10.7 GB – and an exorbitant number of allocations (over 152 million) ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=,particularly%20in%20parse_primary_expression%20and%20parse_binary_expression)). Heaptrack profiling pinpointed two primary culprits: 

- **Excessive Allocations in Parsing:** The parser’s expression parsing routines, especially `parse_primary_expression` and `parse_binary_expression`, were responsible for a **disproportionate share of allocations** ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=,particularly%20in%20parse_primary_expression%20and%20parse_binary_expression)). In fact, these functions dominated the allocation call stack in the profile, indicating that *constructing and storing AST nodes* (e.g. expressions) is causing repeated heap allocations ([memory_profile_report.txt](file://file-PRPWfzRdnRXsG3PwVsr3vp#:~:text=wfl%3A%3Aparser%3A%3AParser%3A%3Aparse_primary_expression%3A%3Ahbefc4b542a84bcf8%20at%20src%2Fparser%2Fmod,rs%3A307)). Likely causes include creating new `Expression` objects for every literal/operand, frequent cloning of token data, and continuously growing `Vec` buffers for expression lists without reusing or reserving capacity. This leads to **unbounded vector reallocations** (many small grows of dynamic arrays) during parsing of complex expressions or long scripts ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=1.%20,allocation%20during%20parsing%20of%20expressions)). In short, the current parser implementation performs a lot of *temporary allocations* that accumulate during a large parse.

- **Reference Cycle Between Environment and Function:** A code review uncovered a potential **Rc reference cycle** involving the interpreter’s `Environment` and user-defined function closures (`FunctionValue`). The global or parent `Environment` holds each function definition in its symbol table (as a `Value::Function(Rc<FunctionValue>)`), and the `FunctionValue` in turn captures a reference to its defining `Environment`. If both sides use strong `Rc` pointers, they form a cycle that **Rust’s reference counting cannot collect** ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=,by%20Rust%27s%20reference%20counting%20system)). This means after functions are defined (especially closures capturing an outer scope), their `Environment` can never be dropped, causing leaked memory for the duration of the program. The heap profile and tests confirm this pattern: e.g. creating deeply nested closures led to memory that remained allocated after those function calls completed, consistent with an environment<->function cycle keeping each other alive. 

- **Unbounded Growth of Data Structures:** The profiling also suggests certain collections grow without bound during execution, contributing to memory bloat ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=,large%20collections%20in%20debug%20reports)). For instance, *vectors that continually resize* (triggering reallocation) were a major source of heap activity ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=,particularly%20in%20parse_primary_expression%20and%20parse_binary_expression)). One suspect is the **debug call stack**: the interpreter maintains a `call_stack: Vec<CallFrame>` for function calls. If call frames are not cleared promptly (or if the debug report retains the entire stack history), this vector could balloon over long or recursive runs ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=,to%20memory%20growth%20during%20execution)). Similarly, large runtime data structures (e.g. very large lists or strings created by the script) and verbose debug logging (dumping entire environments or huge lists) can consume memory if not truncated. The lack of any truncation or limits in debug output means printing a huge list or deeply nested structure will allocate enormous strings in memory. These patterns indicate a need to impose limits on how much data we store or print, to prevent **runaway memory usage** when dealing with large loops or data sets.

## Fix Implementation

To eliminate the leaks and reduce memory footprint, we will implement the following fixes:

- **Break Strong Reference Cycles with `Weak`:** Wherever a cyclic reference exists, convert one side to a non-owning `Weak` pointer. In particular, the closure environment capture should use a `Weak<RefCell<Environment>>` instead of an `Rc`. Currently, the `Environment` already uses a `Weak` for its optional parent link (avoiding parent-child cycles) and we must ensure **functions do the same for their enclosing environment**. We will change the `FunctionValue` struct to hold `env: Weak<RefCell<Environment>>` (if not already done) and update all places that create a `FunctionValue` to call `Rc::downgrade` on the environment. For example: 

  ```rust
  // Define a user function, capturing its defining environment weakly
  let function = FunctionValue {
      name: Some(name.clone()),
      params: param_names,
      body: body.clone(),
      env: Rc::downgrade(&env),           // use Weak pointer to Environment
      line: *line,
      column: *column,
  };
  let function_val = Value::Function(Rc::new(function));
  env.borrow_mut().define(name, function_val.clone());
  ``` 

  In this snippet, `env` is the `Rc<RefCell<Environment>>` for the current scope, and we store a downgraded `Weak` reference inside the function. This ensures the `Environment -> FunctionValue -> Environment` cycle is broken (the back-reference from FunctionValue to Environment no longer increments the refcount) ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=1.%20Break%20Reference%20Cycles%20,env)). After this change, when an environment goes out of scope with only functions closing over it, it can be dropped (the `Weak` in each FunctionValue simply becomes dead). We must carefully audit all code paths that create functions or closures (e.g. action definitions) to use `Rc::downgrade(&env)` instead of `Rc::clone` ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=Rc%3CRefCell%3CEnvironment%3E%3E%20,env)). Similarly, any other potential cycles should be handled (for instance, if *object methods* or other structures ever hold env pointers, those should be weak). This prevents leaked `Environment` instances and their contents after script execution. 

- **Parser Memory Optimizations:** We will refactor the parser to reduce transient allocations and limit growing vectors:

  - *Avoid Unnecessary Cloning:* Many allocations in `parse_primary_expression`/`parse_binary_expression` come from cloning token data (e.g. converting tokens to strings or duplicating values). We can refactor the parser to **borrow token data where possible** instead of cloning. For example, rather than `if let Some(token) = self.tokens.peek().cloned()`, we can peek by reference and match on `&token.token` directly. This way we don’t allocate new token structures on every peek. Similarly, when matching literal tokens, we can use references to the literal values instead of constructing new ones on the heap. Each small reduction will cut down the total allocation count.

  - *Preallocate Vectors and Reuse Buffers:* Wherever the parser builds a `Vec` by pushing in a loop (e.g. collecting function parameters, argument lists, or statements in a block), we should **reserve capacity** or reuse vectors to avoid repeated resizing. For instance, if we parse function call arguments in a loop, we can initialize the vector with an estimated size (if an upper bound is known) or at least call `arguments.reserve(N)` to reduce reallocation frequency. In `parse_primary_expression`, there is a loop collecting arguments after an identifier followed by “with” – we can reserve a small default like 4 or 8 since most functions have only a handful of arguments. This will alleviate the “RawVec reallocation” overhead seen in profiling. Large AST nodes like parse trees for complex expressions might also be built via recursion; we will ensure tail recursion is optimized or switch to iterative parsing for right-associative binary expressions to avoid deep recursion and stack overhead.

  - *String Interning:* To cut down on duplicate string allocations (for example, repeated identifier names or keywords), we can employ **string interning**. This means maintaining a global pool of strings and reusing the same `Rc<String>` or similar for identical text. In practice, when the lexer produces an identifier token, we look it up in an intern pool (e.g. a `HashSet<String>` or `lru_cache`) and use the interned string for the AST. This way, if a variable name like `"count"` appears 1000 times, we allocate it once and reuse the pointer thereafter ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=3,techniques%20to%20reduce%20string%20duplication)). Rust crates or a simple static `Lazy<Mutex<HashSet<String>>>` can support this. Interning will notably reduce memory usage for source code with many repeated identifiers or keywords (common in long loops or repetitive scripts).

  - *Reduce Temporary Objects:* Review the parser’s use of `format!` and error handling. The heaptrace showed a lot of allocations in formatting (likely constructing error messages or debug strings) ([memory_profile_report.txt](file://file-PRPWfzRdnRXsG3PwVsr3vp#:~:text=152593421%20calls%20with%209,gnu%2Flib%2Frustlib%2Fsrc%2Frust%2Flibrary%2Fcore%2Fsrc%2Foption.rs%3A1225%20in%20%2Fhome%2Fubuntu%2Frepos%2Fwfl%2Ftarget%2Fdebug%2Fwfl%20alloc%3A%3Afmt%3A%3Aformat%3A%3Ah723b44785279eb35)). We can minimize this by avoiding string concatenation in tight loops. For example, constructing a parse error can be deferred until an error actually occurs (instead of assembling strings proactively). We will also check if our token and AST data structures can be more memory-efficient (e.g. using enums or numeric representations for keywords instead of full strings). These micro-optimizations will cumulatively reduce the parser’s memory churn.

- **Truncate Debug Output & Large Collections:** To prevent debug and logging features from blowing up memory, we will implement **safe truncation of printed data**. Currently, printing a large `Value` (like a huge list or object) will attempt to format the entire value (recursively printing every element) ([src.md](file://file-X37aF8et8P1ZYHSWKc7t4g#:~:text=Value%3A%3AText%28s%29%20%3D%3E%20write%21%28f%2C%20,)) ([src.md](file://file-X37aF8et8P1ZYHSWKc7t4g#:~:text=write%21%28f%2C%20,0)). We will modify the `fmt::Debug` (and potentially `Display`) implementations for our types (or adjust the `SafeDebug` utility) to impose limits:

  - For **lists and objects** with many elements, print only the first *N* elements and then append an ellipsis. For example, if a list has 1000 items, format maybe the first 16 items and then `"... (984 more)"` ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=2.%20Implement%20Collection%20Truncation%20,items%20to%20prevent%20memory%20explosion)). This way, debugging large collections doesn’t allocate a string for all 1000 items. We can choose a reasonable cutoff (the analysis suggested truncating collections ≥16 items ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=2.%20Implement%20Collection%20Truncation%20,items%20to%20prevent%20memory%20explosion))). Similarly, for long strings, we might print a prefix and `"..."` rather than the full content if it's extremely long.

  - The `SafeDebug` wrapper is already used to limit recursion depth (to avoid infinite loops on self-referential structures) – it stops after depth 4 and prints `"..."` ([src.md](file://file-X37aF8et8P1ZYHSWKc7t4g#:~:text=impl%20fmt%3A%3ADebug%20for%20SafeDebug,return%20write%21%28f%2C)). We will extend this concept to **limit breadth** as well as depth. This means adding a counter in the formatting of lists/objects to break after N entries. We will also ensure `SafeDebug` or our debug printer marks reference cycles clearly (e.g. prints `<cycle>` as it already does for repeated references) ([src.md](file://file-X37aF8et8P1ZYHSWKc7t4g#:~:text=let%20safe_debug%20%3D%20SafeDebug%3A%3Anew,safe_debug)), so we don't infinitely traverse loops.

  - **Limit Debug Report Retention:** The interpreter’s debug report system currently captures the call stack and possibly local variable dumps when an error occurs. We need to make sure this debug info is not kept around longer than needed. Once a report is generated or the program finishes, we should clear any stored call stack traces. If `Interpreter.call_stack` is only needed during execution, we can pop frames as functions return (ensuring the vector doesn’t just grow). In addition, if `debug_report_enabled` is true, we might **disable it for long-running sessions** or provide an option to limit how many entries it records. The goal is to avoid a scenario where every function call is logged and retained forever in memory ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=,to%20memory%20growth%20during%20execution)). By truncating or resetting the call stack info, we free memory incrementally instead of only at the very end.

- **Other Improvements:** We will implement minor tweaks such as bounding certain loops and data structures. For example, in the `count` loop implementation, we have a `max_iterations` set (10000 for normal loops, unlimited for very large ranges relying on timeout) ([src.md](file://file-X37aF8et8P1ZYHSWKc7t4g#:~:text=let%20max_iterations%20%3D%20if%20end_num,let%20mut%20iterations%20%3D%200)). We should enforce reasonable limits to avoid pathological cases that allocate huge amounts of memory in a single run. Likewise, we will review the standard library functions (e.g. pattern matching, list operations) to ensure they don't inadvertently hold onto memory (no lingering references or global caches without eviction). All debugging or logging strings will be built with care for size – e.g., when constructing an error message, if it includes a snippet of user code or data, truncate that snippet to a reasonable length.

By implementing the above changes – breaking cycles, optimizing parse allocations, and adding output limits – we expect to drastically reduce the memory footprint. The changes directly address the known issues (excessive parser allocations and leaks via Rc cycles), while the truncation and limits address potential explosive growth in other areas.

## Test and Validation Strategy

After applying the fixes, we will **verify the memory usage improvements** using both profiling tools and automated tests:

- **Re-run Heap Profiling:** We will run the same scenario (executing the `nexus.wfl` test suite or other heavy workloads) under Heaptrack again to measure the difference. We expect to see a significantly lower peak memory usage and far fewer allocation calls. Specifically, the parse functions should no longer dominate allocations. If our optimizations are effective, the number of allocations in parsing should drop (fewer redundant clones and reserved vectors mean less frequent reallocations). The absence of the environment-function cycle should also reduce memory growth over time – heap usage should plateau instead of climbing continuously. We will compare the new heap profile to the original (10.74GB peak, 152M alloc calls) ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=,particularly%20in%20parse_primary_expression%20and%20parse_binary_expression)) and confirm improvements. Any remaining large allocation hotspots from the profile will be analyzed for further optimization.

- **Memory Leak Unit Tests:** We will expand our test suite with targeted **regression tests for memory leaks**. For example, one existing test creates 10,000 nested functions (deeply recursive closures) and then drops the interpreter, verifying that the global environment’s strong count returns to 1 (meaning no lingering references) ([src.md](file://file-X37aF8et8P1ZYHSWKc7t4g#:~:text=drop)). We will use this pattern to ensure the reference cycle issue is resolved: after defining and using some functions, dropping the `Interpreter` should free everything except the single global environment Rc. We already have a test checking that `Rc::strong_count(&global_env) == 1` after dropping the interpreter (indicating no leaks) ([src.md](file://file-X37aF8et8P1ZYHSWKc7t4g#:~:text=drop)) ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=4.%20Add%20Memory%20Verification%20,objects%20properly%20breaks%20reference%20cycles)) – this test should pass consistently now. We will add similar tests for other potential leaks: for instance, define a function inside another function (closure) and ensure that after returning, no extra env remains; or repeatedly execute a script in the REPL and ensure memory doesn’t accumulate across iterations. We can also leverage Rust’s ability to detect leaks in tests (e.g. enabling `-Z leak-check` or using Valgrind in CI) to catch any unexpected allocations that aren’t freed.

- **Automated Memory Usage Tracking:** In addition to unit tests, we will integrate a **memory usage check** in long-running integration tests. For example, we can run a long loop or recursive call in the interpreter and programmatically monitor memory (via RSS or a custom allocator metric). A simple approach is to call a heavy function (or loop) 1000 times and ensure that the process memory does not grow with each iteration. If available, we might use an instrumented allocator or an OS-specific call (like checking `/proc/<pid>/memory`) at intervals to assert that memory growth stays within expected bounds. These tests would fail if a leak causes continuous growth. We will include these in our CI pipeline so that any reintroduction of a leak is caught early.

- **Benchmarking in REPL and Scripts:** We will conduct performance benchmarks focusing on memory: run the WFL REPL and execute a series of commands (simulate an interactive session) to ensure that memory usage stays roughly constant over time. For example, define and call some functions, create and drop large data structures, and observe that memory is reclaimed. Similarly, run a representative long-running script (with lots of loops or heavy parsing) and measure peak memory vs. final memory. The **expected outcome** is that after script execution completes, the memory should largely be returned to the system (aside from any intentional caching). If we find that memory remains high, that indicates something is still holding references, which we will then debug.

- **Validate Debug Output Limits:** We will test that our debug output truncation works as intended. For instance, create a list of 100 elements and trigger a debug print (perhaps by inserting it into an error message or using a debug command) to see that the output is truncated with "..." and does not allocate an enormous string. We’ll write unit tests for the `fmt::Debug` implementation: e.g., ensure that a list with 20 items produces a string with 16 items and an ellipsis, not all 20. This ensures our safeguard for memory usage in printing is effective and avoids regressions where someone might accidentally remove the limit.

- **Continuous Integration (CI):** We will integrate these memory tests into the CI process. This means the CI will run the memory leak tests (so any future change that causes `Rc::strong_count` to be >1 or memory to grow will result in a test failure). While heap profiling itself might not run on every commit, we can require that every merge passes the leak tests and perhaps periodically run a full heaptrack analysis for major releases. We may also enable tools like Miri or AddressSanitizer in CI in a special job to detect memory issues. For example, running tests with `AddressSanitizer`’s leak checker can automatically fail if memory is leaked at program end. This provides a safety net to catch leaks that slip past manual reference count checks.

By re-profiling and testing in this manner, we will **validate that the memory leaks are fixed** and that the interpreter’s memory usage remains stable. Our goal is to see the memory profile flatline (no unbounded growth) during long runs, and all our new tests passing, indicating that values and environments are properly dropped.

## Long-Term Prevention

To prevent similar memory issues in the future, we will adopt several long-term strategies and best practices:

- **Adopt Defensive Coding Practices:** All developers will be trained to be mindful of Rust’s ownership and reference-counting pitfalls. In particular, when introducing any `Rc<RefCell<T>>` structure, we will **consider potential cycles** upfront. A guideline will be: *if an object needs to refer back to another that already holds it, use `Weak` for the back-reference.* For example, environment-parent links and closure environments use `Weak` – this pattern should be followed for any tree or graph-like structures in the interpreter. We will document this in the project’s contribution guide. Additionally, prefer using Rust’s ownership to avoid long-lived `Rc` where possible (for instance, passing mutable references for temporary data instead of storing in Rc). By designing data structures to be acyclic or breaking cycles with `Weak`, we ensure the drop semantics remain predictable.

- **Regular Memory Profiling in Development:** We will make heap profiling and leak checking a regular part of our development cycle, not just when a problem arises. Developers can use tools like Heaptrack or Valgrind on new features (especially those that allocate frequently, e.g. a new parser module or runtime feature) to catch unexpected growth. We can automate some of this by having a **nightly CI job** that runs a heavy scenario with Heaptrack and compares the results to previous runs. If allocations or memory usage spike, that can flag a potential regression. Even without full automation, periodically running the integration tests under a profiler and storing the reports will help catch trends over time.

- **Enhanced Test Coverage for Memory:** We will expand our suite of **memory-specific tests**. The existing tests for cycles (ensuring reference counts drop) will remain and be supplemented by tests for other structures. For example, we can add a test that creates a self-referential list (if the language allows it) and ensure that our SafeDebug handles it without leaking. We’ll test that very large loops do not exhaust memory: e.g., execute a WFL script that appends to a list in a loop 100,000 times and verify that after the script, the memory usage is bounded (this might be done by checking that the list length is 100,000 but the process did not allocate more than necessary, implying no intermediate leak). By including extreme cases in tests, we put pressure on the interpreter and catch leaks or inefficiencies early. 

- **Code Reviews with a Focus on Memory:** Memory management will be a checklist item in code reviews. Whenever a PR introduces a new `Rc`, `RefCell`, or collection that could grow, reviewers will ask: *Could this create a cycle or unbounded growth?* If a function stores data globally or in a static, we ensure there’s a clear mechanism to free or truncate it. We’ll also encourage use of Rust linters (like Clippy) which can sometimes catch unneeded clones or suggest more efficient patterns. In particular, we might add a custom Clippy lint or just a convention to forbid calling `Rc::clone` in scenarios that look like they could form cycles (one heuristic: cloning an Rc of an environment into a structure that is stored inside that environment is a red flag). While not all such issues can be caught automatically, the team will develop an intuition for these patterns.

- **Continuous Integration Safeguards:** As mentioned, our CI will run memory leak tests. We may enhance this by running tests under memory sanitizers. For example, using `cargo test --release` with environment variable `ASAN_OPTIONS=detect_leaks=1` (AddressSanitizer) or running under `valgrind --leak-check=error` in a CI job can automatically detect if any heap memory was not freed at program exit. This would catch any new reference cycle or forgot-to-drop scenario that our manual tests didn’t cover. We will integrate such a step (perhaps optional or on a schedule, since it can be slow). This way, any introduction of a leak will be immediately flagged to the developer before the code is merged.

- **Monitor Production Usage:** If the WFL interpreter is used in long-running processes or servers, we will monitor their memory over time (using logging or external monitoring). Any sign of memory creeping up will trigger an investigation. We could even build a diagnostic command into the REPL or interpreter (for debug builds) that prints out the current strong counts of global structures or the sizes of key collections, to help spot leaks at runtime. In the long term, if WFL usage patterns become more complex (e.g. users creating data structures that naturally form cycles like graphs), we might consider a more automatic memory management strategy (such as an optional **garbage collector** for cyclic data). However, at this stage, enforcing discipline with `Rc/Weak` and testing should be sufficient.

- **Documentation and Team Knowledge:** We will document the fixes and their rationale in the project README or wiki. Future maintainers should understand why we use `Weak` in certain places, why debug printing is limited, etc. This helps ensure no one “undoes” these safeguards unknowingly. For instance, a comment in `FunctionValue.env` definition will note that it’s a `Weak` to break cycles. Likewise, comments in the debug printing code will explain the truncation logic. By keeping these explanations visible, new contributors are less likely to reintroduce the old mistakes.

In summary, the combination of these preventative measures will keep the WFL interpreter’s memory usage in check. We will catch issues early through testing and profiling, and our coding standards will make memory leaks far less likely. With the reference cycle broken and parser and debug output improved, the interpreter should be able to run large scripts or REPL sessions for long durations **without leaking memory or ballooning in usage**. Our plan not only fixes the current leaks but also establishes a culture of vigilance around memory management, ensuring the WFL interpreter remains efficient and robust in the long run. ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=Conclusion%20The%20memory%20profile%20indicates,consumption%20and%20prevent%20memory%20leaks)) (After applying these changes, the analysis concluded that memory consumption should drop significantly and the leaks be resolved.) 

**Sources:** The findings and recommendations above are based on the WFL project’s heap profiling report and code analysis ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=Memory%20Allocation%20Statistics%20,particularly%20in%20parse_primary_expression%20and%20parse_binary_expression)) ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=,by%20Rust%27s%20reference%20counting%20system)) ([memory_analysis_summary.md](file://file-H1SzKn8ReSEZxNpfvz6rqv#:~:text=1.%20Break%20Reference%20Cycles%20,env)), as well as the current WFL source code and tests ([src.md](file://file-X37aF8et8P1ZYHSWKc7t4g#:~:text=let%20function%20%3D%20FunctionValue%20,column%2C)) ([src.md](file://file-X37aF8et8P1ZYHSWKc7t4g#:~:text=drop)). The implementation plan follows directly from these insights to eliminate the identified memory leaks and prevent their recurrence.